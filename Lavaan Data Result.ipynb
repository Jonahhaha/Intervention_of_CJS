{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f517063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Direct cause\n",
      "Y0_IMP_Behavior ~ Y0_CD * 0.282\n",
      "Y0_IMP_Parents ~ Y0_CD * 0.201\n",
      "Y0_MDD ~ Y0_CD * 0.554\n",
      "Y1_ARREST ~ Y0_CD * 0.081\n",
      "Y1_CD ~ Y0_CD * 0.442\n",
      "Y1_ND ~ Y0_CD * 0.090\n",
      "\n",
      "Indirect cause\n",
      "Y1_IMP_Home ~ Y0_IMP_Parents * 0.387\n",
      "Y0_GAD ~ Y0_MDD * 0.235\n",
      "Y0_PD ~ Y0_MDD * 0.035\n",
      "Y1_MDD ~ Y0_MDD * 0.322\n",
      "Y1_DB_Alone ~ Y1_ARREST * 0.622\n",
      "Y1_DB_Group ~ Y1_ARREST * 0.627\n",
      "Y1_MUD ~ Y1_ARREST * 0.446\n",
      "Y1_DB_Group ~ Y1_CD * 0.097\n",
      "Y1_IMP_Behavior ~ Y1_CD * 0.370\n",
      "Y1_MUD ~ Y1_CD * 0.103\n",
      "Y1_ODD ~ Y1_CD * 0.948\n",
      "Y1_PTSD ~ Y1_CD * 0.221\n",
      "{'M0_CJSI': '0.33232628', 'F0_CJSI': '0.24169184', 'Y0_Male': '0.52265861', 'Y0_Age': '12.61933535', 'Y0_DB_Gen_Del': '0.78851964', 'Y0_DB_SnJ': '1.15407855', 'Y0_ARREST': '0.06042296', 'Y0_PD_Depres': '3.43504532', 'Y0_PD_Suspic': '11.32024169', 'Y0_PD_Cog_Perc_Dys': '6.47129909', 'Y0_PD_Impul': '7.29305136', 'Y0_PD_Eccentr': '8.32326284', 'Y0_PD_Odd_Bel_Exp': '6.63746224', 'Y0_PD_Hostility': '7.18429003', 'Y0_PD_Sep_Insec': '4.30815710', 'Y0_PD_Withdr': '3.27190332', 'Y0_AU_Freq': '0.34441088', 'Y0_AU_Drinks': '0.41389728', 'Y0_AU_4Drinks': '0.20845921', 'Y0_AU_Drunk': '0.21148036', 'Y0_IMP_Home': '3.70392749', 'Y0_IMP_Parents': '1.64652568', 'Y0_IMP_Depr_Anx': '2.22658610', 'Y0_IMP_Behavior': '2.84592145', 'Y0_IMP_Activities': '2.00604230', 'Y0_IMP_Par_Worry': '3.36253776', 'Y0_IMP_Help': '0.91238671', 'Y0_SAD': '2.88368580', 'Y0_PD': '0.39879154', 'Y0_AGOR': '0.42296073', 'Y0_GAD': '2.91238671', 'Y0_PTSD': '0.81268882', 'Y0_MDD': '5.64425982', 'Y0_CD': '1.49848943', 'Y1_ARREST': '0.15407855', 'Y1_DB_Alone': '0.37764350', 'Y1_DB_Group': '0.31722054', 'Y1_DB_Alone_Group': '0.10876133', 'Y1_PD_Susp_Eccentr': '18.44410876', 'Y1_PD_Depres': '3.31722054', 'Y1_PD_Odd_Bel_Exp': '6.56495468', 'Y1_PD_Hostility': '5.11178248', 'Y1_PD_Impul': '12.45317221', 'Y1_PD_Withdr': '3.12688822', 'Y1_PD_Perc_Dys_Sep_Ins': '6.40181269', 'Y1_IMP_Home': '4.24773414', 'Y1_IMP_Activities': '4.05135952', 'Y1_IMP_Behavior': '2.60422961', 'Y1_IMP_Depr_Anx': '1.94561934', 'Y1_IMP_Par_Worry': '3.07250755', 'Y1_IMP_Help': '0.79154079', 'Y1_SAD': '2.06646526', 'Y1_PD': '0.32024169', 'Y1_AGOR': '0.29607251', 'Y1_GAD': '2.45015106', 'Y1_PTSD': '0.61631420', 'Y1_MDD': '4.95015106', 'Y1_CD': '1.33685801', 'Y1_ODD': '3.96072508', 'Y1_AUD': '0.06193353', 'Y1_MUD': '0.24471299', 'Y1_ND': '0.06495468'}\n",
      "To say Y0_CD now is 25 percent, but the relationship should remain the same. The average of Y0_CD is 1.49848943 the decrease part is 1.49848943 * 0.75 = 1.123867\n",
      "\n",
      "\n",
      "Direct cause\n",
      "Y0_IMP_Behavior will decrease 0.316930. The average of Y0_IMP_Behavior used to be 2.84592145, now it will be 2.528991, which decrease by 11.14%.\n",
      "\n",
      "Y0_IMP_Parents will decrease 0.225897. The average of Y0_IMP_Parents used to be 1.64652568, now it will be 1.420628, which decrease by 13.72%.\n",
      "\n",
      "Y0_MDD will decrease 0.622622. The average of Y0_MDD used to be 5.64425982, now it will be 5.021638, which decrease by 11.03%.\n",
      "\n",
      "Y1_ARREST will decrease 0.091033. The average of Y1_ARREST used to be 0.15407855, now it will be 0.063045, which decrease by 59.08%.\n",
      "\n",
      "Y1_CD will decrease 0.496749. The average of Y1_CD used to be 1.33685801, now it will be 0.840109, which decrease by 37.16%.\n",
      "\n",
      "Y1_ND will decrease 0.101148. The average of Y1_ND used to be 0.06495468, now it will be -0.036193, which decrease by 155.72%.\n",
      "\n",
      "\n",
      "Indirect cause\n",
      "Y1_IMP_Home will decrease 0.087422. The average of Y1_IMP_Home used to be 4.24773414, now it will be 4.160312, which decrease by 2.06%.\n",
      "\n",
      "Y0_GAD will decrease 0.146316. The average of Y0_GAD used to be 2.91238671, now it will be 2.76607, which decrease by 5.02%.\n",
      "\n",
      "Y0_PD will decrease 0.021792. The average of Y0_PD used to be 0.39879154, now it will be 0.377, which decrease by 5.46%.\n",
      "\n",
      "Y1_MDD will decrease 0.200484. The average of Y1_MDD used to be 4.95015106, now it will be 4.749667, which decrease by 4.05%.\n",
      "\n",
      "Y1_DB_Alone will decrease 0.056623. The average of Y1_DB_Alone used to be 0.37764350, now it will be 0.321021, which decrease by 14.99%.\n",
      "\n",
      "Y1_IMP_Behavior will decrease 0.183797. The average of Y1_IMP_Behavior used to be 2.60422961, now it will be 2.420432, which decrease by 7.06%.\n",
      "\n",
      "Y1_ODD will decrease 0.470918. The average of Y1_ODD used to be 3.96072508, now it will be 3.489807, which decrease by 11.89%.\n",
      "\n",
      "Y1_PTSD will decrease 0.109782. The average of Y1_PTSD used to be 0.61631420, now it will be 0.506533, which decrease by 17.81%.\n",
      "\n",
      "Variables for two way of causing\n",
      "\n",
      "Y1_MUD will decrease 0.221550 by Y1_ARREST\n",
      "Y1_MUD will decrease 0.051165 by Y1_CD\n",
      "Y1_MUD total decrease is 0.272715. The average of Y1_MUD used to be 0.24471299, now it will be -0.028002, which decrease by 111.44%.\n",
      "\n",
      "Y1_DB_Group will decrease 0.311462 by Y1_ARREST\n",
      "Y1_DB_Group will decrease 0.048185 by Y1_CD\n",
      "Y1_DB_Group total decrease is 0.359647. The average of Y1_DB_Group used to be 0.31722054, now it will be -0.042426, which decrease by 113.37%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "f2 = open('/Users/jonah/Downloads/lab_data/lm_output.txt', \"r\") \n",
    "\n",
    "# Here is the varibale that want to serach\n",
    "varible_need_to_serach = \"Y0_CD\"\n",
    "perctange_change = 25\n",
    "\n",
    "f2_data = f2.readlines() \n",
    "    \n",
    "for line_number, line in enumerate(f2_data, 1):\n",
    "    # Check if the word \"regression\" appears in the line\n",
    "    if \"Regressions:\" in line:\n",
    "        # Print the line number and the line itself\n",
    "        start_line = line_number\n",
    "    if \"Covariances:\" in line:\n",
    "        # Print the line number and the line itself\n",
    "        end_line = line_number\n",
    "\n",
    "part1 = []\n",
    "part2 = []\n",
    "value = []\n",
    "\n",
    "#if line.endswith('~'):\n",
    "\n",
    "for line_number, line in enumerate(f2_data, 1):\n",
    "    if start_line+2 <= line_number <= end_line-2:\n",
    "        if line.strip().endswith('~'):    \n",
    "            part1.append(line.strip())\n",
    "        else:\n",
    "            part2.append(line.split()[0])\n",
    "        # Extract the variable name from line2 \n",
    "            value.append(line.split()[1])\n",
    "        #if \"Regressions:\" in line:\n",
    "        text = re.sub(r'\\s+', ' ', line)\n",
    "        #print(line)\n",
    "    elif line_number > end_line:\n",
    "        break\n",
    "\n",
    "\n",
    "result = []\n",
    "print(\"\\nDirect cause\")\n",
    "# Find the direct cause\n",
    "for i in range(0,len(part1)):\n",
    "    if part2[i] == varible_need_to_serach:\n",
    "        result.append(part1[i-1] +\" \"+ part2[i] +\" * \"+ str(value[i]))\n",
    "        \n",
    "# print the all the cause\n",
    "for cause in result:\n",
    "    print(cause)\n",
    "\n",
    "\n",
    "print(\"\\nIndirect cause\")\n",
    "\n",
    "# Find the indirect cause\n",
    "result2 = []\n",
    "for i in range(0,len(part1)):\n",
    "    if part2[i] == varible_need_to_serach:\n",
    "        for j in range(0,len(part1)):\n",
    "            # need to get rid of the ~\n",
    "            if part2[j] == part1[i-1][:-2]:\n",
    "                result2.append(part1[j-1] +\" \"+ part2[j] +\" * \"+ str(value[j]))\n",
    "\n",
    "for incause in result2:\n",
    "    print(incause) \n",
    "\n",
    "# The average dictionary for each of the variable\n",
    "    \n",
    "file_path = \"/Users/jonah/Downloads/lab_data/mean.txt\"\n",
    "\n",
    "result_dict = {}\n",
    "line_number = 0\n",
    "variable = []\n",
    "value = []\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    # Read each line in the file\n",
    "    for line in file:\n",
    "        line_number = line_number + 1\n",
    "        line = line.strip()\n",
    "        if line_number % 2 == 1:\n",
    "            for x in line.split():\n",
    "                variable.append(x)\n",
    "        else:\n",
    "            for x in line.split():\n",
    "                value.append(x)\n",
    "\n",
    "mean_list = {}\n",
    "\n",
    "# Iterate over the values and variables lists and connect each variable with its corresponding value\n",
    "for variable, value in zip(variable, value):\n",
    "    mean_list[variable] = value\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(mean_list)\n",
    "\n",
    "value_of = mean_list[varible_need_to_serach]\n",
    "decrease_part = float(\"{:.6f}\".format(float(value_of) * ((100-perctange_change)/100)))\n",
    "\n",
    "\n",
    "print(\"To say \" + str(varible_need_to_serach) + \" now is \"+ str(perctange_change) + \" percent, but the relationship should remain the same. The average of \" + str(varible_need_to_serach)+ \" is \"+ str(value_of) + \" the decrease part is \" + str(value_of) + \" * \"+ str(1-perctange_change/100) + \" = \" + str(decrease_part)+\"\\n\")\n",
    "\n",
    "print(\"\\nDirect cause\")\n",
    "\n",
    "for i in result:\n",
    "    words = i.split()\n",
    "    change = float(\"{:.6f}\".format(float(mean_list[words[0]])-float(words[4])*float(decrease_part))) \n",
    "    change_precentage = float(\"{:.2f}\".format(float(words[4])*float(decrease_part)/float(mean_list[words[0]])*100))\n",
    "    print(words[0] + \" will decrease \" + str(\"{:.6f}\".format(float(words[4])*decrease_part))+\". The average of \"+ str(words[0])+\" used to be \"+str(mean_list[words[0]])+\", now it will be \"+ str(change)+\", which decrease by \"+str(change_precentage)+\"%.\\n\")\n",
    "\n",
    "    \n",
    "print(\"\\nIndirect cause\")\n",
    "\n",
    "duplicates = set()\n",
    "unique_list = []\n",
    "# Editing the results list combine the common factor\n",
    "for item in result2:\n",
    "    cf = item.split()\n",
    "    if cf[0] in unique_list:\n",
    "        duplicates.add(cf[0])\n",
    "    else:\n",
    "        unique_list.append(cf[0])\n",
    "               \n",
    "comfa = []\n",
    "for j in result2:\n",
    "    words = j.split()\n",
    "    if words[0] not in duplicates:\n",
    "        for i in result:\n",
    "            find_word = i.split()\n",
    "            if words[2] == find_word[0]:\n",
    "                data = find_word[4]           \n",
    "        change = float(\"{:.6f}\".format(float(mean_list[words[0]])-float(words[4])*decrease_part*float(data))) \n",
    "        change_precentage = float(\"{:.2f}\".format(float(words[4])*float(decrease_part)*float(data)/float(mean_list[words[0]])*100))\n",
    "        print(words[0] + \" will decrease \" + str(\"{:.6f}\".format(float(words[4])*decrease_part*float(data)))+\". The average of \"+ str(words[0])+\" used to be \"+str(mean_list[words[0]])+\", now it will be \"+ str(change)+\", which decrease by \"+str(change_precentage)+\"%.\\n\")\n",
    "    else:\n",
    "        comfa.append(j)\n",
    "        \n",
    "print(\"Variables for two way of causing\\n\") \n",
    "for y in duplicates:\n",
    "    total_change = 0.00\n",
    "    for x in comfa:\n",
    "        words = x.split()\n",
    "        if words[0] == y:\n",
    "            change = float(\"{:.6f}\".format(float(words[4])*decrease_part*float(data)))\n",
    "            total_change = total_change + change\n",
    "            print(words[0] +\" will decrease \"+str(\"{:.6f}\".format(float(words[4])*decrease_part*float(data)))+\" by \"+ words[2])\n",
    "       \n",
    "    change_precentage = float(\"{:.2f}\".format(float(total_change)/float(mean_list[y])*100))\n",
    "    print(y +\" total decrease is \"+str(total_change)+ \". The average of \"+ y +\" used to be \"+ str(mean_list[y])+\", now it will be \"+ str(\"{:.6f}\".format(float(mean_list[y])-total_change))+ \", which decrease by \"+ str(change_precentage) + \"%.\\n\")\n",
    "\n",
    "# consider direct and indirect cause\n",
    "\n",
    "# Y0_CD, Y0_IMP_Behavior adds all the factor impact, \n",
    "# go though variable one by one.\n",
    "\n",
    "# need to work for more than two layers of varibale cause\n",
    "\n",
    "# limition: Y0_CD is variable_A independent variable, then no path. \n",
    "\n",
    "#Erich Kummerfeld\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d4f838a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To say Y0_CD now is 25 percent, but the relationship should remain the same. The average of Y0_CD is 1.49848943 the decrease part is 1.49848943 * 0.75 = 1.123867\n",
      "\n",
      "M0_CJSI Won't change\n",
      "F0_CJSI Won't change\n",
      "Y0_Male Won't change\n",
      "Y0_Age Won't change\n",
      "Y0_DB_Gen_Del Won't change\n",
      "Y0_DB_SnJ Won't change\n",
      "Y0_ARREST Won't change\n",
      "Y0_PD_Depres Won't change\n",
      "Y0_PD_Suspic Won't change\n",
      "Y0_PD_Cog_Perc_Dys Won't change\n",
      "Y0_PD_Impul Won't change\n",
      "Y0_PD_Eccentr Won't change\n",
      "Y0_PD_Odd_Bel_Exp Won't change\n",
      "Y0_PD_Hostility Won't change\n",
      "Y0_PD_Sep_Insec Won't change\n",
      "Y0_PD_Withdr Won't change\n",
      "Y0_AU_Freq Won't change\n",
      "Y0_AU_Drinks Won't change\n",
      "Y0_AU_4Drinks Won't change\n",
      "Y0_AU_Drunk Won't change\n",
      "Y0_IMP_Home Won't change\n",
      "Y0_IMP_Parents will decrease by 13.72%\n",
      "Y0_IMP_Depr_Anx Won't change\n",
      "Y0_IMP_Behavior Won't change\n",
      "Y0_IMP_Activities Won't change\n",
      "Y0_IMP_Par_Worry Won't change\n",
      "Y0_IMP_Help Won't change\n",
      "Y0_SAD Won't change\n",
      "Y0_PD will decrease by 5.46%\n",
      "Y0_AGOR Won't change\n",
      "Y0_GAD will decrease by 1.82%\n",
      "Y0_PTSD Won't change\n",
      "Y0_MDD will decrease by 11.03%\n",
      "Y1_ARREST will decrease by -913.22%\n",
      "Y1_DB_Alone will decrease by 46.72%\n",
      "Y1_DB_Group will decrease by -78.07%\n",
      "Y1_DB_Alone_Group will decrease by -23.0%\n",
      "Y1_PD_Susp_Eccentr will decrease by -0.79%\n",
      "Y1_PD_Depres will decrease by 0.66%\n",
      "Y1_PD_Odd_Bel_Exp Won't change\n",
      "Y1_PD_Hostility Won't change\n",
      "Y1_PD_Impul Won't change\n",
      "Y1_PD_Withdr Won't change\n",
      "Y1_PD_Perc_Dys_Sep_Ins Won't change\n",
      "Y1_IMP_Home will decrease by 2.36%\n",
      "Y1_IMP_Activities Won't change\n",
      "Y1_IMP_Behavior will decrease by 2.12%\n",
      "Y1_IMP_Depr_Anx Won't change\n",
      "Y1_IMP_Par_Worry Won't change\n",
      "Y1_IMP_Help will decrease by 0.21%\n",
      "Y1_SAD will decrease by -13.98%\n",
      "Y1_PD will decrease by -4.06%\n",
      "Y1_AGOR Won't change\n",
      "Y1_GAD will decrease by 0.42%\n",
      "Y1_PTSD will decrease by 5.94%\n",
      "Y1_MDD will decrease by 5.23%\n",
      "Y1_CD will decrease by 37.16%\n",
      "Y1_ODD will decrease by 11.89%\n",
      "Y1_AUD will decrease by 272.81%\n",
      "Y1_MUD will decrease by -165.91%\n",
      "Y1_ND will decrease by 155.72%\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "f2 = open('/Users/jonah/Downloads/lab_data/lm_output.txt', \"r\") \n",
    "with open('/Users/jonah/Downloads/lab_data/final_variable_change_output.txt', 'w') as fileout:\n",
    "    # Here is the varibale that want to serach\n",
    "    varible_need_to_serach = \"Y0_CD\"\n",
    "    perctange_change = 25\n",
    "    f2_data = f2.readlines() \n",
    "\n",
    "    for line_number, line in enumerate(f2_data, 1):\n",
    "        # Check if the word \"regression\" appears in the line\n",
    "        if \"Regressions:\" in line:\n",
    "            # Print the line number and the line itself\n",
    "            start_line = line_number\n",
    "        if \"Covariances:\" in line:\n",
    "            # Print the line number and the line itself\n",
    "            end_line = line_number\n",
    "\n",
    "    part1 = []\n",
    "    part2 = []\n",
    "    value_list = []\n",
    "    result = []\n",
    "\n",
    "    for line_number, line in enumerate(f2_data, 1):\n",
    "        if start_line+2 <= line_number <= end_line-2:\n",
    "            if line.strip().endswith('~'):    \n",
    "                part1.append(line.strip())\n",
    "            else:\n",
    "                part2.append(line.split()[0])\n",
    "            # Extract the variable name from line2 \n",
    "                value_list.append(line.split()[1])\n",
    "            text = re.sub(r'\\s+', ' ', line)\n",
    "        elif line_number > end_line:\n",
    "            break\n",
    "\n",
    "    for i in range(0,len(part1)):\n",
    "        result.append(part1[i-1] +\" \"+ part2[i] +\" * \"+ str(value_list[i]))\n",
    "\n",
    "    f3 = open('/Users/jonah/Downloads/lab_data/Jonah_Y0_Y1_Model_3.csv1_final_copy.txt',\"r\")\n",
    "    x = f3.readline()\n",
    "    variable_list = []\n",
    "    for i in x.split():\n",
    "        variable_list.append(i)\n",
    "\n",
    "    result_final = []\n",
    "\n",
    "    for i in range(0,len(variable_list)):\n",
    "        result = []\n",
    "        for x in range(0,len(part1)):\n",
    "            if part2[x] == variable_list[i]:\n",
    "                result.append(part1[x][:-2])\n",
    "        result_final.append(result)\n",
    "\n",
    "    result_dict = {k: v for k, v in zip(variable_list, result_final)}\n",
    "\n",
    "    def find_all_paths(graph, start, end):\n",
    "        queue = deque([(start, [start])])\n",
    "        all_paths = []\n",
    "\n",
    "        while queue:\n",
    "            current_node, path = queue.popleft()\n",
    "\n",
    "            if current_node == end:\n",
    "                all_paths.append(path)\n",
    "                continue\n",
    "\n",
    "            for neighbor in graph[current_node]:\n",
    "                if neighbor not in path:\n",
    "                    queue.append((neighbor, path + [neighbor]))\n",
    "\n",
    "        return all_paths\n",
    "\n",
    "    # Find all paths between start and end nodes\n",
    "    result_path = []\n",
    "\n",
    "    for i in variable_list:\n",
    "        if i != varible_need_to_serach:\n",
    "            paths = find_all_paths(result_dict, varible_need_to_serach, i)\n",
    "            result_path.append(paths)\n",
    "\n",
    "    # The average dictionary for each of the variable\n",
    "\n",
    "    file_path = \"/Users/jonah/Downloads/lab_data/mean.txt\"\n",
    "    line_number = 0\n",
    "    variable = []\n",
    "    value = []\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Read each line in the file\n",
    "        for line in file:\n",
    "            line_number = line_number + 1\n",
    "            line = line.strip()\n",
    "            if line_number % 2 == 1:\n",
    "                for x in line.split():\n",
    "                    variable.append(x)\n",
    "            else:\n",
    "                for x in line.split():\n",
    "                    value.append(x)\n",
    "\n",
    "    mean_list = {}\n",
    "\n",
    "    # Iterate over the values and variables lists and connect each variable with its corresponding value\n",
    "    for variable, value in zip(variable, value):\n",
    "        mean_list[variable] = value\n",
    "\n",
    "    value_of = mean_list[varible_need_to_serach]\n",
    "\n",
    "    decrease_part = float(\"{:.6f}\".format(float(value_of) * ((100-perctange_change)/100)))\n",
    "\n",
    "    print(\"To say \" + str(varible_need_to_serach) + \" now is \"+ str(perctange_change) + \" percent, but the relationship should remain the same. The average of \" + str(varible_need_to_serach)+ \" is \"+ str(value_of) + \" the decrease part is \" + str(value_of) + \" * \"+ str(1-perctange_change/100) + \" = \" + str(decrease_part)+\"\\n\")\n",
    "    fileout.write(\"To say \" + str(varible_need_to_serach) + \" now is \"+ str(perctange_change) + \" percent, but the relationship should remain the same. The average of \" + str(varible_need_to_serach)+ \" is \"+ str(value_of) + \" the decrease part is \" + str(value_of) + \" * \"+ str(1-perctange_change/100) + \" = \" + str(decrease_part)+\"\\n\")\n",
    "    index_to_remove = variable_list.index(varible_need_to_serach)\n",
    "    removed_string = variable_list.pop(index_to_remove)\n",
    "\n",
    "\n",
    "    # Find all paths between start and end nodes and check to see if tehre is any from the casue. \n",
    "    result_path_check = []\n",
    "\n",
    "    for i in variable_list:\n",
    "        if i != varible_need_to_serach:\n",
    "            paths = find_all_paths(result_dict, i, varible_need_to_serach)\n",
    "            result_path_check.append(paths)\n",
    "\n",
    "    result_path_check_variable = []\n",
    "    for q in range(0,len(result_path_check)):\n",
    "        if result_path_check[q] == []:\n",
    "            continue\n",
    "        else:\n",
    "            for w in result_path_check[q]:\n",
    "                result_path_check_variable.append(w[0])\n",
    "\n",
    "    #Edit the result_path to delete some casue variable relationships\n",
    "    for x in range(0, len(result_path)):\n",
    "        if result_path[x] ==[]:\n",
    "            continue\n",
    "        else:\n",
    "            for y in result_path[x]:\n",
    "                for l in range(0,len(y)-1):\n",
    "                    if y[l] in result_path_check_variable:\n",
    "                        result_path[x].remove(y)\n",
    "\n",
    "    # print out the final result\n",
    "    for x in range(0, len(result_path)):\n",
    "        if result_path[x] ==[]:\n",
    "            print(str(variable_list[x] +\" Won't change\"))\n",
    "            fileout.write(str(variable_list[x] +\" Won't change\\n\"))\n",
    "        else:\n",
    "            total_change = 0.00\n",
    "            for y in result_path[x]:\n",
    "                mult = 1\n",
    "                for l in range(0,len(y)-1):\n",
    "                    index_num = part2.index(y[l]) and part1.index(y[l+1]+\" ~\")\n",
    "                    mult = mult * float(value_list[index_num+1])\n",
    "                change = float(\"{:.6f}\".format(mult*float(decrease_part)))\n",
    "                total_change = total_change + change\n",
    "            change_precentage = float(\"{:.2f}\".format(float(total_change)/float(mean_list[variable_list[x]])*100))\n",
    "            print(variable_list[x] + \" will decrease by \"+str(change_precentage)+\"%\")\n",
    "            fileout.write(variable_list[x] + \" will decrease by \"+str(change_precentage)+\"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "975fd795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All paths between A and F: [['A', 'B', 'E', 'F'], ['A', 'C', 'F'], ['A', 'F']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_all_paths(graph, start, end, path=[]):\n",
    "    # Add the current node to the path\n",
    "    path = path + [start]\n",
    "    \n",
    "    # If the start node is the same as the end node, return the path\n",
    "    if start == end:\n",
    "        return [path]\n",
    "    \n",
    "    # If the start node is not in the graph, return an empty list\n",
    "    if start not in graph:\n",
    "        return []\n",
    "    \n",
    "    # Initialize a list to store all paths\n",
    "    paths = []\n",
    "    \n",
    "    # Iterate over neighbors of the start node\n",
    "    for node in graph[start]:\n",
    "        # Check if the neighbor has already been visited\n",
    "        if node not in path:\n",
    "            # Recursively find paths from the neighbor to the end node\n",
    "            new_paths = find_all_paths(graph, node, end, path)\n",
    "            # Extend the current path with the new paths found\n",
    "            paths.extend(new_paths)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# Define start and end nodes\n",
    "start_node = 'A'\n",
    "end_node = 'F'\n",
    "\n",
    "# Find all paths between start and end nodes\n",
    "paths = find_all_paths(graph, start_node, end_node)\n",
    "\n",
    "# Print all paths found\n",
    "print(\"All paths between {} and {}: {}\".format(start_node, end_node, paths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
